{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a05111614164fa79fb0d8a8c999170a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64d02a026ae0457f9c851be5fbf1b5f5",
              "IPY_MODEL_d70b5422066f4ad3b62d269b751941cf",
              "IPY_MODEL_f6abd995ecd34940a30ccd5786799393"
            ],
            "layout": "IPY_MODEL_7c090c293ccf4517834bf61ba6448a32"
          }
        },
        "64d02a026ae0457f9c851be5fbf1b5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edaadafcad0e4f00840d6e36989621f5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e37cf800b8ed4d59b228d8df58ca8a67",
            "value": "100%"
          }
        },
        "d70b5422066f4ad3b62d269b751941cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03450dd1aecd448fab609d6587aad109",
            "max": 580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6168b01d0a9e4f1088dbb0bd3e5b9dd0",
            "value": 580
          }
        },
        "f6abd995ecd34940a30ccd5786799393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7732c4ffadd346b7b8599e084eecb27c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4ab29d07d4ee4fa1b7e1fbac393dcc4b",
            "value": " 580/580 [00:00&lt;00:00, 5912.70it/s]"
          }
        },
        "7c090c293ccf4517834bf61ba6448a32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edaadafcad0e4f00840d6e36989621f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37cf800b8ed4d59b228d8df58ca8a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03450dd1aecd448fab609d6587aad109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6168b01d0a9e4f1088dbb0bd3e5b9dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7732c4ffadd346b7b8599e084eecb27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab29d07d4ee4fa1b7e1fbac393dcc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qhF7Oi9c-v6"
      },
      "source": [
        " # Module 2a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JouKR3pTBF_L"
      },
      "source": [
        "# *Online Dermatologists:* ðŸ“± ðŸŒ Diagnosing Skin Cancer through a Web Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPnF7JnsD6II"
      },
      "source": [
        "In this project, we will be be diagnosing skin lesion images for signs of skin cancer. To perform this task, we'll be working with an array of machine learning methods and models.\n",
        "\n",
        "We're hoping that our model might be useful to people who don't have easy access to medical professionals. For that, it'll need to be both highly accurate and easily accessible! Yesterday's simple models didn't perform well enough for this job.\n",
        "\n",
        "In this notebook we'll be:\n",
        "*   Developing more complex ML models using Convolutional Neural Networks\n",
        "*   Deploying our ML models to a web app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ObbA3WmI798"
      },
      "source": [
        "# Set up our Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih8pc-WDIxbx",
        "outputId": "b6227be1-e7fd-4228-e768-bd9633e8377a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Run this to download data and prepare our environment! { display-mode: \"form\" }\n",
        "print(\"Installing packages...\")\n",
        "!pip install hypopt tensorflowjs > /dev/null\n",
        "print(\"Downloading files...\")\n",
        "!wget https://www.dropbox.com/s/fedqcdt4o0m2oxp/X.npy &> /dev/null\n",
        "!wget https://www.dropbox.com/s/h7xh92w1w7px30a/X_g.npy &> /dev/null\n",
        "!wget https://www.dropbox.com/s/grn9brfvzx74c8a/y.npy &> /dev/null\n",
        "print(\"Importing stuff...\")\n",
        "import os\n",
        "os.makedirs(\"static/js\", exist_ok=True)\n",
        "!wget -O static/js/skin_cancer_diagnosis_script.js 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/skin_cancer_diagnosis_script.js' &> /dev/null\n",
        "output = 'static/js/skin_cancer_diagnosis_script.js'\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import gdown\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model\n",
        "import struct\n",
        "from google.colab.patches import cv2_imshow\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "\n",
        "from hypopt import GridSearch\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import requests, io, zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "import os.path\n",
        "from os import path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing packages...\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Downloading files...\n",
            "Importing stuff...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITfh4GjlttRH"
      },
      "source": [
        "IMG_WIDTH = 100\n",
        "IMG_HEIGHT = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMVUe5bs_2uX"
      },
      "source": [
        "Let's load in our data from last time!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpq4DXFN6cRf"
      },
      "source": [
        "X = np.load(\"X.npy\")\n",
        "X_g = np.load(\"X_g.npy\")\n",
        "y = np.load(\"y.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC4VupwgyqpN",
        "outputId": "da5e6eee-8a07-4d2b-c782-affa3dfd8b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1a05111614164fa79fb0d8a8c999170a",
            "64d02a026ae0457f9c851be5fbf1b5f5",
            "d70b5422066f4ad3b62d269b751941cf",
            "f6abd995ecd34940a30ccd5786799393",
            "7c090c293ccf4517834bf61ba6448a32",
            "edaadafcad0e4f00840d6e36989621f5",
            "e37cf800b8ed4d59b228d8df58ca8a67",
            "03450dd1aecd448fab609d6587aad109",
            "6168b01d0a9e4f1088dbb0bd3e5b9dd0",
            "7732c4ffadd346b7b8599e084eecb27c",
            "4ab29d07d4ee4fa1b7e1fbac393dcc4b"
          ]
        }
      },
      "source": [
        "#@title Run this to Perform Data Augmentation { display-mode: \"form\" }\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "X_g_train, X_g_test, y_train, y_test = train_test_split(X_g, y, test_size=0.4, random_state=101)\n",
        "\n",
        "X_augmented = []\n",
        "X_g_augmented = []\n",
        "\n",
        "y_augmented = []\n",
        "\n",
        "for i in tqdm(range(len(X_train))):\n",
        "  transform = random.randint(0,1)\n",
        "  if (transform == 0):\n",
        "    # Flip the image across the y-axis\n",
        "    X_augmented.append(cv2.flip(X_train[i],1))\n",
        "    X_g_augmented.append(cv2.flip(X_g_train[i],1))\n",
        "    y_augmented.append(y_train[i])\n",
        "  else:\n",
        "    # Zoom 33% into the image\n",
        "    zoom = 0.33\n",
        "\n",
        "    centerX,centerY=int(IMG_HEIGHT/2),int(IMG_WIDTH/2)\n",
        "    radiusX,radiusY= int((1-zoom)*IMG_HEIGHT*2),int((1-zoom)*IMG_WIDTH*2)\n",
        "\n",
        "    minX,maxX=centerX-radiusX,centerX+radiusX\n",
        "    minY,maxY=centerY-radiusY,centerY+radiusY\n",
        "\n",
        "    cropped = (X_train[i])[minX:maxX, minY:maxY]\n",
        "    new_img = cv2.resize(cropped, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    X_augmented.append(new_img)\n",
        "\n",
        "    cropped = (X_g_train[i])[minX:maxX, minY:maxY]\n",
        "    new_img = cv2.resize(cropped, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    X_g_augmented.append(new_img)\n",
        "\n",
        "    y_augmented.append(y_train[i])\n",
        "\n",
        "X_augmented = np.array(X_augmented)\n",
        "X_g_augmented = np.array(X_g_augmented)\n",
        "\n",
        "y_augmented = np.array(y_augmented)\n",
        "\n",
        "X_train = np.vstack((X_train,X_augmented))\n",
        "X_g_train = np.vstack((X_g_train,X_g_augmented))\n",
        "\n",
        "y_train = np.append(y_train,y_augmented)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/580 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a05111614164fa79fb0d8a8c999170a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwVcrhcDDE7h"
      },
      "source": [
        "Let's view the shape of our training variables after data augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2yCz4Cqc9U5"
      },
      "source": [
        "#Your Code Here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZThMze80XRW"
      },
      "source": [
        "# Creating Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8yRJmUHkqWw"
      },
      "source": [
        "**Now**, let's explore some alternative classification options."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WAr9_wa1AXX"
      },
      "source": [
        "Let's take a look at Convolutional Neural Networks. These machine learning models are tailor made to work with images through the use of *Convolutional Layers*.\n",
        "\n",
        "CNNs contain several kinds of layers; some of the most important are the *Convolutional Layers*, *Pooling Layers*, and *Fully Connected Layers*.\n",
        "\n",
        "The Convolutional Layer is used to extract features from the image through the use of a sliding window, known as a kernel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE55_4A6OgiP"
      },
      "source": [
        "![alt text](https://stanford.edu/~shervine/teaching/cs-230/illustrations/convolution-layer-a.png?1c517e00cb8d709baf32fc3d39ebae67)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJJzjq1VOkCe"
      },
      "source": [
        "\n",
        "The Pooling Layer reduces the dimensions of the image, and extracts the most important features. This layer is very useful in minimizing overfitting, as a lot of the features that are too specific to the training data will be discarded in this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JATieE3K1A6X"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/875/1*KQIEqhxzICU7thjaQBfPBQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkZ5aeG0OT9O"
      },
      "source": [
        "Finally, after multiple iterations of Convolutional and Pooling Layers, the image is converted to a classification probability in the fully connected layer. The fully connected layer is architecturally similar to a traditional neural network. The input to this component is our flattened image (after all the transformations from the Convolutional and Pooling layers are applied), and the outputs are the predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Mqv1hwOwYu"
      },
      "source": [
        "\n",
        "![alt text](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/74_blog_image_1.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swoyff2uRp82"
      },
      "source": [
        "# Your Response Here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P15J_c6gxnxI"
      },
      "source": [
        "We'll use the the library Keras to create the models for our skin lesion classification. Let's start off by creating our own CNN model (This is the same model we used in the earlier Intro to CNNs notebook). We can work with our color images with the CNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysnigm4YO-Ua"
      },
      "source": [
        "Take a look at the CNN's definition below.\n",
        "\n",
        "**Question**: How is the model organized? Could you draw a diagram of its structure?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB0G7k4jO7Tm"
      },
      "source": [
        "# Your Response Here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfVye7oWuNMM"
      },
      "source": [
        "def CNNClassifier(epochs=20, batch_size=10, layers=5, dropout=0.5, activation='relu'):\n",
        "  def set_params():\n",
        "    i = 1\n",
        "  def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(layers):\n",
        "      model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "      model.add(Activation(activation))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout / 2.0))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Conv2D(128, (3, 3)))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout / 2.0))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(7))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=[tf.keras.metrics.AUC()])\n",
        "    return model\n",
        "  return KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDsvw0vZPYDm"
      },
      "source": [
        "Some terms you might notice include Epochs, Batch Size, Learning Rate, Dropout, and Activation functions:\n",
        "\n",
        "\n",
        "*   Dropout is a method of preventing overfitting by randomly ignoring certain neurons from the model during training.\n",
        "*   Activation functions determine how a neuron calculates its output after adding up its weighted inputs.\n",
        "*   Epochs are just the number of iterations we would like to train our model for.\n",
        "*   Batch Size is the number of samples we would like to send through the model at a time.\n",
        "*   The Learning Rate is a hyperparameter that affects how quickly the model changes to adapt to the training data.\n",
        "\n",
        "Phew, that was a lot of terms!\n",
        "\n",
        "**Question:** With your knowledge so far, what values would you set these parameters to be? What might your model's architecture look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M33InjU0cybr"
      },
      "source": [
        "# Your Response Here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1kKW8jm1m24"
      },
      "source": [
        "We also need to transform our y labels into one hot encoded labels for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPCxQjeS1Qjk"
      },
      "source": [
        "y_train_onehot = np.zeros((y_train.size, y_train.max().astype(int)+1))\n",
        "y_train_onehot[np.arange(y_train.size),y_train.astype(int)] = 1\n",
        "\n",
        "y_test_onehot = np.zeros((y_test.size, y_test.max().astype(int)+1))\n",
        "y_test_onehot[np.arange(y_test.size),y_test.astype(int)] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWHMBqfzkBVM"
      },
      "source": [
        "Let's initialize and train our CNN. This may take a while to execute as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_blzuQQyiJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe592c2-b729-446a-f2c9-e7be0e875648"
      },
      "source": [
        "cnn = CNNClassifier()\n",
        "\n",
        "cnn.fit(X_train.astype(np.float32), y_train_onehot.astype(np.float32),\n",
        "        validation_data=(X_test.astype(np.float32),y_test_onehot.astype(np.float32))\n",
        "        ,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "116/116 [==============================] - 25s 56ms/step - loss: 3.8236 - auc: 0.6060 - val_loss: 1.8517 - val_auc: 0.6139\n",
            "Epoch 2/20\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 1.7086 - auc: 0.7141 - val_loss: 1.5904 - val_auc: 0.8051\n",
            "Epoch 3/20\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 1.4909 - auc: 0.8063 - val_loss: 1.4641 - val_auc: 0.8260\n",
            "Epoch 4/20\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 1.3726 - auc: 0.8445 - val_loss: 1.4832 - val_auc: 0.8116\n",
            "Epoch 5/20\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 1.2506 - auc: 0.8753 - val_loss: 1.6110 - val_auc: 0.8189\n",
            "Epoch 6/20\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 1.1763 - auc: 0.8892 - val_loss: 1.4082 - val_auc: 0.8426\n",
            "Epoch 7/20\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 1.0607 - auc: 0.9082 - val_loss: 1.4663 - val_auc: 0.8307\n",
            "Epoch 8/20\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.9859 - auc: 0.9206 - val_loss: 1.4775 - val_auc: 0.8251\n",
            "Epoch 9/20\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.9807 - auc: 0.9289 - val_loss: 1.4913 - val_auc: 0.8260\n",
            "Epoch 10/20\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.8353 - auc: 0.9449 - val_loss: 1.3086 - val_auc: 0.8721\n",
            "Epoch 11/20\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.7767 - auc: 0.9499 - val_loss: 1.3542 - val_auc: 0.8668\n",
            "Epoch 12/20\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.7082 - auc: 0.9592 - val_loss: 1.8625 - val_auc: 0.8415\n",
            "Epoch 13/20\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.6205 - auc: 0.9672 - val_loss: 1.4793 - val_auc: 0.8720\n",
            "Epoch 14/20\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.5662 - auc: 0.9735 - val_loss: 1.5672 - val_auc: 0.8584\n",
            "Epoch 15/20\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.5589 - auc: 0.9733 - val_loss: 1.5169 - val_auc: 0.8708\n",
            "Epoch 16/20\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.4885 - auc: 0.9811 - val_loss: 1.7352 - val_auc: 0.8657\n",
            "Epoch 17/20\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.4267 - auc: 0.9830 - val_loss: 1.7282 - val_auc: 0.8526\n",
            "Epoch 18/20\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.3821 - auc: 0.9857 - val_loss: 2.0261 - val_auc: 0.8434\n",
            "Epoch 19/20\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.3230 - auc: 0.9898 - val_loss: 2.4242 - val_auc: 0.8409\n",
            "Epoch 20/20\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.3269 - auc: 0.9877 - val_loss: 1.8384 - val_auc: 0.8568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb0b02c9a50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NniM-5heGlsh"
      },
      "source": [
        "Let's save and download our trained model, so that we can use it in a web app later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNiX3iRXTLoz"
      },
      "source": [
        "tfjs.converters.save_keras_model(cnn.model, 'cnn_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6p-1f4H-WyO"
      },
      "source": [
        "**Let's evaluate our model's performance!** Let's start by defining our `model_stats()` and `plot_cm()` functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdgFEDo82dYQ"
      },
      "source": [
        "#@title Click here to define `model_stats()`! { display-mode: \"form\" }\n",
        "def model_stats(name, y_test, y_pred, y_pred_proba):\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  print(name)\n",
        "\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  print (\"The accuracy of the model is \" + str(round(accuracy,5)))\n",
        "\n",
        "  y_test_onehot = np.zeros((y_test.size, y_test.max().astype(int)+1))\n",
        "  y_test_onehot[np.arange(y_test.size),y_test.astype(int)] = 1\n",
        "\n",
        "  roc_score = roc_auc_score(y_test_onehot, y_pred_proba)\n",
        "\n",
        "  print (\"The ROC AUC Score of the model is \" + str(round(roc_score,5)))\n",
        "\n",
        "  return cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvsanDVh3tJ_"
      },
      "source": [
        "How can we use this function to evaluate our model? Code your answer below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1LVV03hvWI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab40d65-309f-4cd4-8e44-fedfac595a73"
      },
      "source": [
        "# Your code here!\n",
        "y_pred = cnn.predict(X_test)\n",
        "y_test_proba = cnn.predict_proba(X_test)\n",
        "cnn_cm = model_stats(cnn, y_test, y_pred, y_test_proba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fb02c76b190>\n",
            "The accuracy of the model is 0.35659\n",
            "The ROC AUC Score of the model is 0.64468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHweJLDq2hJO"
      },
      "source": [
        "#@title Let's also redefine the `plot_cm()` function from our first notebook. { display-mode: \"form\" }\n",
        "def plot_cm(name, cm):\n",
        "  classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "\n",
        "  df_cm = pd.DataFrame(cm, index = [i for i in classes], columns = [i for i in classes])\n",
        "  df_cm = df_cm.round(5)\n",
        "\n",
        "  plt.figure(figsize = (12,8))\n",
        "  sns.heatmap(df_cm, annot=True, fmt='g')\n",
        "  plt.title(name + \" Model Confusion Matrix\")\n",
        "  plt.xlabel(\"Predicted Label\")\n",
        "  plt.ylabel(\"True Label\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es3RakSP49Tj"
      },
      "source": [
        "Let's use the function to plot a confusion matrix of our model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN6xRVnLvY9n"
      },
      "source": [
        "# Your code here!\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j89i4MY0RSm"
      },
      "source": [
        "It looks like our custom CNN's performance is better than the KNN and Decision Tree models. More training epochs or a bigger dataset would probably help with the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPtcDPJjF9KF"
      },
      "source": [
        "Try building your own CNN! Let's see who can get the best performance in your group!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUX0Etpsrnik"
      },
      "source": [
        "### First, define your model here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eFkna-TGCB0"
      },
      "source": [
        "def CNNClassifier_Modified(epochs=20, batch_size=10, layers=5, dropout=0.5, activation='relu'):\n",
        "  def set_params():\n",
        "    i = 1\n",
        "  def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Your Code Here\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(7))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=[tf.keras.metrics.AUC()])\n",
        "    return model\n",
        "  return KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PPhn_GNrvgq"
      },
      "source": [
        "### Then, run the code below to train your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1tJLItEGR70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a68ffc-efb6-4878-a8e5-905eaa5def30"
      },
      "source": [
        "cnn = CNNClassifier_Modified()\n",
        "\n",
        "cnn.fit(X_train.astype(np.float32), y_train_onehot.astype(np.float32),\n",
        "        validation_data=(X_test.astype(np.float32),y_test_onehot.astype(np.float32))\n",
        "        ,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 2s 15ms/step - loss: 413.5667 - auc_1: 0.5208 - val_loss: 283.8616 - val_auc_1: 0.5526\n",
            "Epoch 2/20\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 327.9242 - auc_1: 0.5521 - val_loss: 440.3037 - val_auc_1: 0.5628\n",
            "Epoch 3/20\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 314.1118 - auc_1: 0.5632 - val_loss: 233.9820 - val_auc_1: 0.5721\n",
            "Epoch 4/20\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 299.2789 - auc_1: 0.5709 - val_loss: 282.3857 - val_auc_1: 0.6108\n",
            "Epoch 5/20\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 309.2667 - auc_1: 0.5701 - val_loss: 291.5676 - val_auc_1: 0.6139\n",
            "Epoch 6/20\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 287.5487 - auc_1: 0.5894 - val_loss: 162.4478 - val_auc_1: 0.6370\n",
            "Epoch 7/20\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 277.4281 - auc_1: 0.6045 - val_loss: 247.1803 - val_auc_1: 0.5993\n",
            "Epoch 8/20\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 261.0422 - auc_1: 0.5997 - val_loss: 170.7198 - val_auc_1: 0.6107\n",
            "Epoch 9/20\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 278.2005 - auc_1: 0.6015 - val_loss: 161.7706 - val_auc_1: 0.6615\n",
            "Epoch 10/20\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 258.3879 - auc_1: 0.6084 - val_loss: 301.2998 - val_auc_1: 0.5588\n",
            "Epoch 11/20\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 265.5111 - auc_1: 0.6119 - val_loss: 573.2862 - val_auc_1: 0.4996\n",
            "Epoch 12/20\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 256.3191 - auc_1: 0.6052 - val_loss: 304.8883 - val_auc_1: 0.6128\n",
            "Epoch 13/20\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 268.1956 - auc_1: 0.6033 - val_loss: 245.6378 - val_auc_1: 0.6260\n",
            "Epoch 14/20\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 256.1506 - auc_1: 0.6262 - val_loss: 338.1030 - val_auc_1: 0.5836\n",
            "Epoch 15/20\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 262.0628 - auc_1: 0.6162 - val_loss: 434.8915 - val_auc_1: 0.5349\n",
            "Epoch 16/20\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 252.3908 - auc_1: 0.6272 - val_loss: 322.1724 - val_auc_1: 0.5966\n",
            "Epoch 17/20\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 245.4099 - auc_1: 0.6296 - val_loss: 212.2590 - val_auc_1: 0.6205\n",
            "Epoch 18/20\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 247.4792 - auc_1: 0.6295 - val_loss: 252.2009 - val_auc_1: 0.6463\n",
            "Epoch 19/20\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 229.9768 - auc_1: 0.6331 - val_loss: 272.9915 - val_auc_1: 0.6325\n",
            "Epoch 20/20\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 236.9966 - auc_1: 0.6387 - val_loss: 249.8134 - val_auc_1: 0.6236\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb02d7c7110>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2easqS-JviIS"
      },
      "source": [
        "### Next, let's evaluate your model's performance!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dSZrUKzGUZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8046ac2a-6af2-4bfe-fb71-575a3ab608a0"
      },
      "source": [
        "y_pred = cnn.predict(X_test)\n",
        "y_pred_proba = cnn.predict_proba(X_test)\n",
        "cnn_cm = model_stats(\"CNN\",y_test,y_pred,y_pred_proba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN\n",
            "The accuracy of the model is 0.35659\n",
            "The ROC AUC Score of the model is 0.64468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVnNteSEvp3x"
      },
      "source": [
        "### Finally, we can plot our confusion matrix below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6DWNF-AGWQr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "b1200e40-4987-4456-87e3-31ecdbcddfac"
      },
      "source": [
        "plot_cm(\"CNN\", cnn_cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK-jmPIbELKO"
      },
      "source": [
        "Let's try using a grid search with our CNN. A note to instructors, this section may take a long time to execute so it's better if students come back to this portion on their own time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSbd6nVW8qnK"
      },
      "source": [
        "In the variable `param_grid` we can specify which parameters in our CNN we want to modify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9sLO2ozhbEp"
      },
      "source": [
        "param_grid = {\n",
        "              'epochs' :              [10, 20, 30],\n",
        "              'batch_size' :          [32, 64,128],\n",
        "              'layers' :              [1, 3, 5],\n",
        "              'dropout' :             [0.2, 0.3, 0.5],\n",
        "              'activation' :          ['relu', 'elu']\n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUZ5HOnoFdur"
      },
      "source": [
        "With this parameter grid we would be training 162 different models! This is because the total number of hyperparameter combinations is calculated as `3 * 3 * 3 * 3 * 2`. For testing out our grid search, let's redefine our parameter grid to just have four possible combinations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3RbPa_cXV90"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6O6O1kOzw45"
      },
      "source": [
        "Let's create a validation slice in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq58SXMGz21Q"
      },
      "source": [
        "X_test_small, X_val, y_test_small, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhvYxtNbFASa"
      },
      "source": [
        "Here we've created a class for our Grid Search Classifier that can be used by the hypopt library for generating various models with different hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzz_Dod38c09"
      },
      "source": [
        "#@title Run this to Define our Grid Search CNN Class { display-mode: \"form\" }\n",
        "class gridSearchCNN():\n",
        "\n",
        "    keras_model = None\n",
        "    model = Sequential()\n",
        "    #epochs=10\n",
        "    epochs=1\n",
        "    batch_size=10\n",
        "    layers=5\n",
        "    dropout=0.5\n",
        "    activation='relu'\n",
        "\n",
        "    def __init__(self, **params):\n",
        "      pass\n",
        "\n",
        "    def fit(self, X, y, sample_weight = None):\n",
        "        print(\"fitting\")\n",
        "        self.keras_model.fit(X,y)\n",
        "        print(\"fitted\")\n",
        "        return self.keras_model\n",
        "    def predict(self, X):\n",
        "        return self.keras_model.predict(X)\n",
        "    def predict_proba(self, X):\n",
        "        return self.keras_model.predict_proba(X)\n",
        "    def score(self, X, y, sample_weight = None):\n",
        "        print(\"scoring\")\n",
        "        #return self.keras_model.score(X,y)\n",
        "        y_pred_proba = self.keras_model.predict_proba(X)\n",
        "        roc_auc_score_val = roc_auc_score(y, y_pred_proba)\n",
        "        print(\"scored\")\n",
        "        return roc_auc_score_val\n",
        "\n",
        "\n",
        "    def createKerasCNN(self,):\n",
        "\n",
        "      def create_model():\n",
        "        self.model = Sequential()\n",
        "\n",
        "        for i in range(self.layers):\n",
        "          self.model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "          self.model.add(Activation(self.activation))\n",
        "\n",
        "        self.model.add(Conv2D(64, (3, 3)))\n",
        "        self.model.add(Activation(self.activation))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.model.add(Dropout(self.dropout / 2.0))\n",
        "\n",
        "        self.model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "        self.model.add(Activation(self.activation))\n",
        "        self.model.add(Conv2D(128, (3, 3)))\n",
        "        self.model.add(Activation(self.activation))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.model.add(Dropout(self.dropout / 2.0))\n",
        "\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(512))\n",
        "        self.model.add(Activation(self.activation))\n",
        "        self.model.add(Dropout(self.dropout))\n",
        "        self.model.add(Dense(7))\n",
        "        self.model.add(Activation('softmax'))\n",
        "\n",
        "        # initiate RMSprop optimizer\n",
        "        opt = optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "        # Let's train the model using RMSprop\n",
        "        self.model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=opt,\n",
        "                      metrics=[tf.keras.metrics.AUC()])\n",
        "        return self.model\n",
        "\n",
        "      return KerasClassifier(build_fn=create_model, epochs=self.epochs,\n",
        "                            batch_size=self.batch_size, verbose=2)\n",
        "\n",
        "    def get_params(self, deep = True):\n",
        "        return {\n",
        "            'epochs': self.epochs,\n",
        "            'batch_size': self.batch_size,\n",
        "            'layers': self.layers,\n",
        "            'dropout': self.dropout,\n",
        "            'activation': self.activation\n",
        "            }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "      if 'epochs' in params.keys():\n",
        "        self.epochs = params['epochs']\n",
        "      if 'batch_size' in params.keys():\n",
        "        self.batch_size = params['batch_size']\n",
        "      if 'layers' in params.keys():\n",
        "        self.layers = params['layers']\n",
        "      if 'dropout' in params.keys():\n",
        "        self.dropout = params['dropout']\n",
        "      if 'activation' in params.keys():\n",
        "        self.activation = params['activation']\n",
        "\n",
        "      self.keras_model = self.createKerasCNN()\n",
        "      return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMGPIzKqkOQO"
      },
      "source": [
        "Now let's implement our grid search to identify our optimal model parameters.\n",
        "\n",
        "**Note:** This may take very long to run (around 11 minutes), so it might be a good idea to come back to this later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSdY_2_PvwNd"
      },
      "source": [
        "gs = GridSearch(model=gridSearchCNN(),param_grid=param_grid,parallelize=False)\n",
        "# Your Code Here\n",
        "\n",
        "# End Code\n",
        "y_train_onehot = np.zeros((y_train.size, y_train.max().astype(int)+1))\n",
        "y_train_onehot[np.arange(y_train.size),y_train.astype(int)] = 1\n",
        "\n",
        "y_val_onehot = np.zeros((y_val.size, y_val.max().astype(int)+1))\n",
        "y_val_onehot[np.arange(y_val.size),y_val.astype(int)] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sov5qvd49gZ1"
      },
      "source": [
        "Let's evaluate our model with our testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUi61PjX9lS2"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69xnmWMM-IVp"
      },
      "source": [
        "Let's also plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MedHDGHE-OLo"
      },
      "source": [
        "# Your Code Here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxzSJIvvhC_I"
      },
      "source": [
        "#Transfer Learning\n",
        "\n",
        "Now, let's try implementing *transfer learning.* This a form of machine learning where we take an existing pre-trained network and modify the weights for the top level neurons by training on our dataset. Here, we'll use the MobileNet model as a basis for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_JkoWrRwJms"
      },
      "source": [
        "def transfer_learning_model():\n",
        "  mobilenet_model = MobileNet(input_shape=(IMG_HEIGHT,IMG_WIDTH,3), include_top=False, pooling=\"max\")\n",
        "\n",
        "  transfer_model = Sequential()\n",
        "  transfer_model.add(mobilenet_model)\n",
        "  transfer_model.add(Dropout(0.1))\n",
        "  transfer_model.add(BatchNormalization())\n",
        "  transfer_model.add(Dense(256, activation=\"relu\"))\n",
        "  transfer_model.add(Dropout(0.1))\n",
        "  transfer_model.add(BatchNormalization())\n",
        "  transfer_model.add(Dense(7, activation=\"softmax\"))\n",
        "\n",
        "  # initiate RMSprop optimizer\n",
        "  opt = optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "  # Let's train the model using RMSprop\n",
        "  transfer_model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=[tf.keras.metrics.AUC()])\n",
        "\n",
        "  return transfer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p31AQxYW_rhq"
      },
      "source": [
        "We no longer need the validation dataset as we aren't tweaking any hyperparameters anymore, so we can use our original, bigger `X_test` dataset that includes the validation data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yInf5HpxGlvR"
      },
      "source": [
        "Let's confirm that our training and testing variables are the right shapes. Once again, we'll use the one-hot encoded variables for the output: `y_test_roc` and `y_train_roc`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y000oRyf-yRy"
      },
      "source": [
        "Let's define our `transfer_model` and train it below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0NmNz5L_Rku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720532d3-8308-4b21-daa2-da737e29bd35"
      },
      "source": [
        "transfer_model = KerasClassifier(build_fn=transfer_learning_model, verbose=1, epochs=20)\n",
        "# Your Code Here\n",
        "y_train_roc = transfer_model.fit(X_train, y_train)\n",
        "y_test_roc = transfer_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "37/37 [==============================] - 7s 37ms/step - loss: 1.8588 - auc_7: 0.7262\n",
            "Epoch 2/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.9989 - auc_7: 0.9153\n",
            "Epoch 3/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.5945 - auc_7: 0.9725\n",
            "Epoch 4/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.4063 - auc_7: 0.9890\n",
            "Epoch 5/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.2756 - auc_7: 0.9951\n",
            "Epoch 6/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.1838 - auc_7: 0.9983\n",
            "Epoch 7/20\n",
            "37/37 [==============================] - 1s 32ms/step - loss: 0.1406 - auc_7: 0.9989\n",
            "Epoch 8/20\n",
            "37/37 [==============================] - 1s 34ms/step - loss: 0.1006 - auc_7: 0.9991\n",
            "Epoch 9/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0740 - auc_7: 0.9996\n",
            "Epoch 10/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0559 - auc_7: 0.9998\n",
            "Epoch 11/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0412 - auc_7: 1.0000\n",
            "Epoch 12/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0331 - auc_7: 1.0000\n",
            "Epoch 13/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0327 - auc_7: 0.9999\n",
            "Epoch 14/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0260 - auc_7: 1.0000\n",
            "Epoch 15/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0262 - auc_7: 1.0000\n",
            "Epoch 16/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0307 - auc_7: 1.0000\n",
            "Epoch 17/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0157 - auc_7: 1.0000\n",
            "Epoch 18/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0171 - auc_7: 1.0000\n",
            "Epoch 19/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0272 - auc_7: 1.0000\n",
            "Epoch 20/20\n",
            "37/37 [==============================] - 1s 33ms/step - loss: 0.0216 - auc_7: 0.9995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAQXleqU_DEy"
      },
      "source": [
        "Let's also observe its performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmemnv5RDf4_"
      },
      "source": [
        "# Your Code Here\n",
        "accuracy = accuracy_score()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcjLUgpa_E-e"
      },
      "source": [
        "Let's take a look at the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n_p4h60ADL1"
      },
      "source": [
        "# Your Code Here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5fUPqfuAhoE"
      },
      "source": [
        "Great, looks like this model performed the best! **Question:** Why would that be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjPeKGhNAnj6"
      },
      "source": [
        "# Your Response Here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYNCn41kApnl"
      },
      "source": [
        "Now that we've created our model, let's save it to a file we can load up later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtGN1E9tN2A0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "8fec37fd-90fa-49b2-e434-58e59eae3a01"
      },
      "source": [
        "tfjs.converters.save_keras_model(transfer_model.model, 'transfer_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2fa4ed9b480b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transfer_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6v4v5r8Dw0j"
      },
      "source": [
        " Now, the model should be saved to your computer through your browser. Unfortunately, tensorflowjs doesn't support this version of MobileNet, so we'll have to use our first CNN model for the website deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIwaTfNvDXo0"
      },
      "source": [
        "Great work! We've just developed various ML models to perform classification on our skin lesion dataset! Now, our next step is to package this model into a mobile application. Run the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX6OKDjzyvVP"
      },
      "source": [
        "!zip -r ./cnn_model.zip ./cnn_model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on_CQSbjPSZJ"
      },
      "source": [
        "After the line of code above finishes executing, click on the folder icon on the left, click the three dots to the left of ```cnn_model.zip```, and download it to your computer. Downloading might take a while! If you choose to deploy your model on the web, you'll be uploading this file to colab notebook 2b so that you can deploy our first CNN model!"
      ]
    }
  ]
}